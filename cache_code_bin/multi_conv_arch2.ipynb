{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import spacy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from live_plot import LivePlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./../sampled_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = np.array(df['reviewText'])\n",
    "labels = np.array(df['overall']).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in texts:\n",
    "  if type(text) != str:\n",
    "    print(text)\n",
    "    print('warning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "def prepare_texts(texts):\n",
    "    text_matrices = []\n",
    "    docs = nlp.pipe(texts, batch_size=1000)\n",
    "    for doc in docs:\n",
    "        mat = np.array([token.vector for token in doc])\n",
    "        mat = torch.tensor(mat, dtype=torch.float32)\n",
    "        text_matrices.append(mat)\n",
    "        \n",
    "    return text_matrices\n",
    "\n",
    "text_matrices = prepare_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(text_matrices, 'text_matrices.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_matrices_loaded = torch.load('text_matrices.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_matrices_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 300])\n",
      "torch.Size([33, 300])\n",
      "torch.Size([39, 300])\n",
      "torch.Size([244, 300])\n",
      "torch.Size([59, 300])\n",
      "torch.Size([7, 300])\n",
      "torch.Size([82, 300])\n",
      "torch.Size([131, 300])\n",
      "torch.Size([9, 300])\n",
      "torch.Size([66, 300])\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(text_matrices[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 300])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_matrices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = np.array(df['reviewText'])\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "def prepare_text(text):\n",
    "  doc = nlp(text)\n",
    "  vectors =  torch.tensor(np.array(doc.vector), dtype=torch.float32)\n",
    "  return vectors\n",
    "\n",
    "texts_matrices = [prepare_text(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "def prepare_text(text):\n",
    "  doc = nlp(text)\n",
    "  vectors =  torch.tensor(np.array([token.vector for token in doc]), dtype=torch.float32)\n",
    "  return vectors\n",
    "\n",
    "texts_matrices = [prepare_text(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_vec = np.vectorize(prepare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m text_matrices2 \u001b[38;5;241m=\u001b[39m \u001b[43mpt_vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\dev\\VENVs\\.ml-pytorch1\\Lib\\site-packages\\numpy\\lib\\function_base.py:2372\u001b[0m, in \u001b[0;36mvectorize.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2369\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_stage_2(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m-> 2372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_as_normal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\dev\\VENVs\\.ml-pytorch1\\Lib\\site-packages\\numpy\\lib\\function_base.py:2365\u001b[0m, in \u001b[0;36mvectorize._call_as_normal\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2362\u001b[0m     vargs \u001b[38;5;241m=\u001b[39m [args[_i] \u001b[38;5;28;01mfor\u001b[39;00m _i \u001b[38;5;129;01min\u001b[39;00m inds]\n\u001b[0;32m   2363\u001b[0m     vargs\u001b[38;5;241m.\u001b[39mextend([kwargs[_n] \u001b[38;5;28;01mfor\u001b[39;00m _n \u001b[38;5;129;01min\u001b[39;00m names])\n\u001b[1;32m-> 2365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vectorize_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\dev\\VENVs\\.ml-pytorch1\\Lib\\site-packages\\numpy\\lib\\function_base.py:2458\u001b[0m, in \u001b[0;36mvectorize._vectorize_call\u001b[1;34m(self, func, args)\u001b[0m\n\u001b[0;32m   2455\u001b[0m outputs \u001b[38;5;241m=\u001b[39m ufunc(\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m   2457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mnout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 2458\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43motypes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2460\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([asanyarray(x, dtype\u001b[38;5;241m=\u001b[39mt)\n\u001b[0;32m   2461\u001b[0m                  \u001b[38;5;28;01mfor\u001b[39;00m x, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(outputs, otypes)])\n",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "text_matrices2 = pt_vec(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'string' has incorrect type (expected str, got numpy.str_)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m texts_matrices \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mpt_vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m texts_matrices \u001b[38;5;241m=\u001b[39m [\u001b[43mpt_vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts]\n",
      "File \u001b[1;32mc:\\dev\\VENVs\\.ml-pytorch1\\Lib\\site-packages\\numpy\\lib\\function_base.py:2372\u001b[0m, in \u001b[0;36mvectorize.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2369\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_stage_2(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m-> 2372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_as_normal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\dev\\VENVs\\.ml-pytorch1\\Lib\\site-packages\\numpy\\lib\\function_base.py:2365\u001b[0m, in \u001b[0;36mvectorize._call_as_normal\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2362\u001b[0m     vargs \u001b[38;5;241m=\u001b[39m [args[_i] \u001b[38;5;28;01mfor\u001b[39;00m _i \u001b[38;5;129;01min\u001b[39;00m inds]\n\u001b[0;32m   2363\u001b[0m     vargs\u001b[38;5;241m.\u001b[39mextend([kwargs[_n] \u001b[38;5;28;01mfor\u001b[39;00m _n \u001b[38;5;129;01min\u001b[39;00m names])\n\u001b[1;32m-> 2365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vectorize_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\dev\\VENVs\\.ml-pytorch1\\Lib\\site-packages\\numpy\\lib\\function_base.py:2450\u001b[0m, in \u001b[0;36mvectorize._vectorize_call\u001b[1;34m(self, func, args)\u001b[0m\n\u001b[0;32m   2448\u001b[0m     res \u001b[38;5;241m=\u001b[39m func()\n\u001b[0;32m   2449\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2450\u001b[0m     ufunc, otypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_ufunc_and_otypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2452\u001b[0m     \u001b[38;5;66;03m# Convert args to object arrays first\u001b[39;00m\n\u001b[0;32m   2453\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m [asanyarray(a, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args]\n",
      "File \u001b[1;32mc:\\dev\\VENVs\\.ml-pytorch1\\Lib\\site-packages\\numpy\\lib\\function_base.py:2410\u001b[0m, in \u001b[0;36mvectorize._get_ufunc_and_otypes\u001b[1;34m(self, func, args)\u001b[0m\n\u001b[0;32m   2406\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcannot call `vectorize` on size 0 inputs \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2407\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munless `otypes` is set\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2409\u001b[0m inputs \u001b[38;5;241m=\u001b[39m [arg\u001b[38;5;241m.\u001b[39mflat[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m-> 2410\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2412\u001b[0m \u001b[38;5;66;03m# Performance note: profiling indicates that -- for simple\u001b[39;00m\n\u001b[0;32m   2413\u001b[0m \u001b[38;5;66;03m# functions at least -- this wrapping can almost double the\u001b[39;00m\n\u001b[0;32m   2414\u001b[0m \u001b[38;5;66;03m# execution time.\u001b[39;00m\n\u001b[0;32m   2415\u001b[0m \u001b[38;5;66;03m# Hence we make it optional.\u001b[39;00m\n\u001b[0;32m   2416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache:\n",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m, in \u001b[0;36mprepare_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_text\u001b[39m(text):\n\u001b[1;32m----> 4\u001b[0m   doc \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m   vectors \u001b[38;5;241m=\u001b[39m  torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray([token\u001b[38;5;241m.\u001b[39mvector \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc]), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      6\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m vectors\n",
      "File \u001b[1;32mc:\\dev\\VENVs\\.ml-pytorch1\\Lib\\site-packages\\spacy\\language.py:1037\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1018\u001b[0m     text: Union[\u001b[38;5;28mstr\u001b[39m, Doc],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1021\u001b[0m     component_cfg: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, Any]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1022\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Doc:\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply the pipeline to some text. The text can span multiple sentences,\u001b[39;00m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;124;03m    and can contain arbitrary whitespace. Alignment into the original string\u001b[39;00m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;124;03m    is preserved.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;124;03m    DOCS: https://spacy.io/api/language#call\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1037\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1038\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m component_cfg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1039\u001b[0m         component_cfg \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\dev\\VENVs\\.ml-pytorch1\\Lib\\site-packages\\spacy\\language.py:1128\u001b[0m, in \u001b[0;36mLanguage._ensure_doc\u001b[1;34m(self, doc_like)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m doc_like\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(doc_like, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m-> 1128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc_like\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(doc_like, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Doc(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab)\u001b[38;5;241m.\u001b[39mfrom_bytes(doc_like)\n",
      "File \u001b[1;32mc:\\dev\\VENVs\\.ml-pytorch1\\Lib\\site-packages\\spacy\\language.py:1120\u001b[0m, in \u001b[0;36mLanguage.make_doc\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length:\n\u001b[0;32m   1117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1118\u001b[0m         Errors\u001b[38;5;241m.\u001b[39mE088\u001b[38;5;241m.\u001b[39mformat(length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(text), max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length)\n\u001b[0;32m   1119\u001b[0m     )\n\u001b[1;32m-> 1120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: Argument 'string' has incorrect type (expected str, got numpy.str_)"
     ]
    }
   ],
   "source": [
    "texts_matrices = [pt_vec(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequence(texts_matrices, batch_first=True)\n",
    "y = torch.tensor(labels, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing a shape of X because pytorch's conv1d takes the second dimension as channels (and we want word features to be channels and slide by ngram words crops)\n",
    "\n",
    "X = X.movedim(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 300, 358])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_size = 0.15\n",
    "test_size = 0.15\n",
    "\n",
    "bord1 = int(len(X) * (1 - (dev_size + test_size)))\n",
    "bord2 = int(len(X) * (1 - test_size))\n",
    "\n",
    "X_train, X_dev, X_test = X[:bord1].to(device), X[bord1:bord2].to(device), X[bord2:]\n",
    "y_train, y_dev, y_test = y[:bord1].to(device), y[bord1:bord2].to(device), y[bord2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, input_data, labels):\n",
    "        self.input_data = input_data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CustomDataset(X_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=256, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = X_train.shape[1]\n",
    "input_len = X_train.shape[2]\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterable\n",
    "\n",
    "class Multiple1DConv(nn.Module):\n",
    "  def __init__(self, input_channels: int, out_channels: int = 64, kernel_sizes: Iterable[int] = (3, 4, 5)):\n",
    "    super().__init__()\n",
    "\n",
    "    self.multiple_1d_convs = nn.ModuleList()\n",
    "\n",
    "    for kernel_size in kernel_sizes:\n",
    "\n",
    "      self.multiple_1d_convs.append(\n",
    "        nn.Sequential(\n",
    "          nn.Conv1d(input_channels, out_channels,\n",
    "                kernel_size=kernel_size, padding=(kernel_size // 2)),\n",
    "          nn.AdaptiveMaxPool1d(1)\n",
    "        )\n",
    "      )\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    outputs = torch.concat([conv_1d_max(inputs) for conv_1d_max in self.multiple_1d_convs], dim=1)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mulpiple1DBinaryClass(nn.Module):\n",
    "  def __init__(self, input_channels, output_size, kernel_sizes=(3, 4, 5), out_channels=64):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.multiple_cnn_max_linear_relu_sigmoid = nn.Sequential(\n",
    "      Multiple1DConv(input_channels, out_channels=out_channels, kernel_sizes=kernel_sizes),\n",
    "\n",
    "      nn.Flatten(),\n",
    "\n",
    "      nn.Linear(out_channels * len(kernel_sizes), 256),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(256, 256),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(256, output_size),\n",
    "      nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.multiple_cnn_max_linear_relu_sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Mulpiple1DBinaryClass(input_channels, output_size, kernel_sizes=(3, 4, 5, 6, 7), out_channels=64).to(device)\n",
    "\n",
    "train_loss_histroty = []\n",
    "dev_loss_history = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625793"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.utils.parameters_to_vector(model.parameters()).numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0000003, weight_decay=2, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "%matplotlib qt\n",
    "live_plot = LivePlot(slice_prop=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train loss: 0.12367183715105057; Dev loss: 0.2571112811565399\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "  for epoch in range(epochs):\n",
    "    model.train()\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for (X_batch, y_batch) in train_dl:\n",
    "      batch_outputs = model(X_batch)\n",
    "      loss_batch = loss_fn(batch_outputs, y_batch)\n",
    "      loss_batch.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "      model.eval()\n",
    "      # measure train and dev loss at the end of epoch\n",
    "      train_outputs = model(X_train)\n",
    "      train_loss = loss_fn(train_outputs, y_train)\n",
    "      train_loss_histroty.append(train_loss.item())\n",
    "\n",
    "      dev_outputs = model(X_dev)\n",
    "      dev_loss = loss_fn(dev_outputs, y_dev)\n",
    "      dev_loss_history.append(dev_loss.item())\n",
    "\n",
    "      print(f'Train loss: {train_loss}; Dev loss: {dev_loss}')\n",
    "      live_plot.update(train_loss_histroty, dev_loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(train_loss_histroty)\n",
    "plt.plot(dev_loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), './models/best_model_mc_cnn_arch2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X_test, y_test):\n",
    "  with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    X_test = X_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "\n",
    "    print('ACCRURACIES:')\n",
    "    accuracies = []\n",
    "\n",
    "    Xs = [X_train, X_dev, X_test]\n",
    "    ys = [y_train, y_dev, y_test]\n",
    "    comments = ['1) Train', '2) Dev', '3) Test']\n",
    "\n",
    "    for x_i, y_i, comment in zip(Xs, ys, comments):\n",
    "      output = model(x_i).to('cpu')\n",
    "      labels_pred = torch.tensor([round(val.item()) for val in output], device='cpu')\n",
    "\n",
    "\n",
    "      y_true = y_i.clone().to('cpu').reshape(-1)\n",
    "\n",
    "      accuracy = (labels_pred == y_true).sum().item() / y_i.shape[0]\n",
    "      accuracies.append(accuracy)\n",
    "\n",
    "      print(comment)\n",
    "      print((labels_pred == y_true).sum().item(), '/', len(y_true))\n",
    "      print(round(accuracy*100, 3), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCRURACIES:\n",
      "1) Train\n",
      "6869 / 7000\n",
      "98.129 %\n",
      "2) Dev\n",
      "1346 / 1500\n",
      "89.733 %\n",
      "3) Test\n",
      "1349 / 1500\n",
      "89.933 %\n"
     ]
    }
   ],
   "source": [
    "test(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCRURACIES:\n",
      "1) Train\n",
      "6863 / 7000\n",
      "98.043 %\n",
      "2) Dev\n",
      "1343 / 1500\n",
      "89.533 %\n",
      "3) Test\n",
      "1350 / 1500\n",
      "90.0 %\n"
     ]
    }
   ],
   "source": [
    "test(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ml-pytorch1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
